{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>83.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>Female</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Urban</td>\n",
       "      <td>125.20</td>\n",
       "      <td>40.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>Female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>82.99</td>\n",
       "      <td>30.6</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>Male</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>166.29</td>\n",
       "      <td>25.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>Female</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Govt_job</td>\n",
       "      <td>Urban</td>\n",
       "      <td>85.28</td>\n",
       "      <td>26.2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5109 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender   age  hypertension  heart_disease ever_married      work_type  \\\n",
       "0       Male  67.0             0              1          Yes        Private   \n",
       "1     Female  61.0             0              0          Yes  Self-employed   \n",
       "2       Male  80.0             0              1          Yes        Private   \n",
       "3     Female  49.0             0              0          Yes        Private   \n",
       "4     Female  79.0             1              0          Yes  Self-employed   \n",
       "...      ...   ...           ...            ...          ...            ...   \n",
       "5104  Female  80.0             1              0          Yes        Private   \n",
       "5105  Female  81.0             0              0          Yes  Self-employed   \n",
       "5106  Female  35.0             0              0          Yes  Self-employed   \n",
       "5107    Male  51.0             0              0          Yes        Private   \n",
       "5108  Female  44.0             0              0          Yes       Govt_job   \n",
       "\n",
       "     Residence_type  avg_glucose_level   bmi   smoking_status  stroke  \n",
       "0             Urban             228.69  36.6  formerly smoked       1  \n",
       "1             Rural             202.21   NaN     never smoked       1  \n",
       "2             Rural             105.92  32.5     never smoked       1  \n",
       "3             Urban             171.23  34.4           smokes       1  \n",
       "4             Rural             174.12  24.0     never smoked       1  \n",
       "...             ...                ...   ...              ...     ...  \n",
       "5104          Urban              83.75   NaN     never smoked       0  \n",
       "5105          Urban             125.20  40.0     never smoked       0  \n",
       "5106          Rural              82.99  30.6     never smoked       0  \n",
       "5107          Rural             166.29  25.6  formerly smoked       0  \n",
       "5108          Urban              85.28  26.2          Unknown       0  \n",
       "\n",
       "[5109 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('stroke.csv', sep=';', decimal='.')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                object\n",
       "age                  float64\n",
       "hypertension           int64\n",
       "heart_disease          int64\n",
       "ever_married          object\n",
       "work_type             object\n",
       "Residence_type        object\n",
       "avg_glucose_level    float64\n",
       "bmi                  float64\n",
       "smoking_status        object\n",
       "stroke                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['heart_disease'].fillna(df['heart_disease'].interpolate(), inplace=True)\n",
    "df['avg_glucose_level'].fillna(df['avg_glucose_level'].interpolate(), inplace=True)\n",
    "df['bmi'].fillna(df['bmi'].interpolate(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "numerical_columns = [col for col in df.columns if col not in categorical_columns + ['stroke']]\n",
    "x_numeric = df[numerical_columns]\n",
    "x_categorical = df[categorical_columns]\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "x_categorical_encoded = x_categorical.apply(encoder.fit_transform)\n",
    "\n",
    "X = pd.concat([x_numeric, x_categorical_encoded], axis=1)\n",
    "df.drop(['stroke'], axis=1)\n",
    "y = df['stroke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UdziaÅ‚ negatywny: 0.9542\n",
      "UdziaÅ‚ pozytywny: 0.0458\n"
     ]
    }
   ],
   "source": [
    "udzial_pozytywny_train = y_train.sum() / len(y_train)\n",
    "udzial_negatywny_train = 1 - udzial_pozytywny_train\n",
    "print(f'UdziaÅ‚ negatywny: {udzial_negatywny_train:.4f}')\n",
    "print(f'UdziaÅ‚ pozytywny: {udzial_pozytywny_train:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UdziaÅ‚ negatywny: 0.9393\n",
      "UdziaÅ‚ pozywtny: 0.0607\n"
     ]
    }
   ],
   "source": [
    "udzial_pozytywny_test = y_test.sum() / len(y_test)\n",
    "udzial_negatywny_test = 1 - udzial_pozytywny_test\n",
    "print(f'UdziaÅ‚ negatywny: {udzial_negatywny_test:.4f}')\n",
    "print(f'UdziaÅ‚ pozywtny: {udzial_pozytywny_test:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DokÅ‚adnoÅ›Ä‡ KNN: 93.05%\n",
      "Raport klasyfikacji dla modelu KNN:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       960\n",
      "           1       0.15      0.03      0.05        62\n",
      "\n",
      "    accuracy                           0.93      1022\n",
      "   macro avg       0.55      0.51      0.51      1022\n",
      "weighted avg       0.89      0.93      0.91      1022\n",
      "\n",
      "Specificity: 0.9885416666666667\n",
      "Sensitivity: 0.03225806451612903\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(f'DokÅ‚adnoÅ›Ä‡ KNN: {accuracy_knn:.2%}')\n",
    "\n",
    "classification_report_knn = classification_report(y_test, y_pred_knn)\n",
    "print(f'Raport klasyfikacji dla modelu KNN: {classification_report_knn}')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_knn)\n",
    "true_negatives = conf_matrix[0, 0]\n",
    "false_positives = conf_matrix[0, 1]\n",
    "\n",
    "specificity = true_negatives / (true_negatives + false_positives)\n",
    "print(f'Specificity: {specificity}')\n",
    "\n",
    "true_positives = conf_matrix[1, 1]\n",
    "false_negatives = conf_matrix[1, 0]\n",
    "\n",
    "sensitivity = true_positives / (true_positives + false_negatives)\n",
    "print(f'Sensitivity: {sensitivity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model regresji logistycznej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DokÅ‚adnoÅ›Ä‡ LR: 93.93%\n",
      "Raport klasyfikacji dla modelu LR:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       960\n",
      "           1       0.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.94      1022\n",
      "   macro avg       0.47      0.50      0.48      1022\n",
      "weighted avg       0.88      0.94      0.91      1022\n",
      "\n",
      "Specificity: 1.0\n",
      "Sensitivity: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KamilSarzyniak\\anaconda3\\envs\\py10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\KamilSarzyniak\\anaconda3\\envs\\py10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\KamilSarzyniak\\anaconda3\\envs\\py10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(f'DokÅ‚adnoÅ›Ä‡ LR: {accuracy_lr:.2%}')\n",
    "\n",
    "classification_report_lr = classification_report(y_test, y_pred_lr)\n",
    "print(f'Raport klasyfikacji dla modelu LR: {classification_report_lr}')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_lr)\n",
    "true_negatives = conf_matrix[0, 0]\n",
    "false_positives = conf_matrix[0, 1]\n",
    "\n",
    "specificity = true_negatives / (true_negatives + false_positives)\n",
    "print(f'Specificity: {specificity}')\n",
    "\n",
    "true_positives = conf_matrix[1, 1]\n",
    "false_negatives = conf_matrix[1, 0]\n",
    "\n",
    "sensitivity = true_positives / (true_positives + false_negatives)\n",
    "print(f'Sensitivity: {sensitivity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling dla algorytmu KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z oversamplingiem:\n",
      "DokÅ‚adnoÅ›Ä‡: 88.55%\n",
      "Raport klasyfikacji:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       960\n",
      "           1       0.15      0.19      0.17        62\n",
      "\n",
      "    accuracy                           0.89      1022\n",
      "   macro avg       0.55      0.56      0.55      1022\n",
      "weighted avg       0.90      0.89      0.89      1022\n",
      "\n",
      "Specificity: 0.9302083333333333\n",
      "Sensitivity: 0.1935483870967742\n"
     ]
    }
   ],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X_train_over, y_train_over = oversample.fit_resample(X_train, y_train)\n",
    "knn_model_over = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model_over.fit(X_train_over, y_train_over)\n",
    "y_pred_over_knn = knn_model_over.predict(X_test)\n",
    "accuracy_over_knn = accuracy_score(y_test, y_pred_over_knn)\n",
    "report_over_knn = classification_report(y_test, y_pred_over_knn)\n",
    "print(f'Z oversamplingiem:')\n",
    "print(f'DokÅ‚adnoÅ›Ä‡: {accuracy_over_knn:.2%}')\n",
    "print(f'Raport klasyfikacji: {report_over_knn}')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_over_knn)\n",
    "true_negatives = conf_matrix[0, 0]\n",
    "false_positives = conf_matrix[0, 1]\n",
    "\n",
    "specificity = true_negatives / (true_negatives + false_positives)\n",
    "print(f'Specificity: {specificity}')\n",
    "\n",
    "true_positives = conf_matrix[1, 1]\n",
    "false_negatives = conf_matrix[1, 0]\n",
    "\n",
    "sensitivity = true_positives / (true_positives + false_negatives)\n",
    "print(f'Sensitivity: {sensitivity}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling dla algorytmu KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z undersamplingiem:\n",
      "DokÅ‚adnoÅ›Ä‡: 88.55%\n",
      "Raport klasyfikacji:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.65      0.78       960\n",
      "           1       0.12      0.71      0.20        62\n",
      "\n",
      "    accuracy                           0.66      1022\n",
      "   macro avg       0.54      0.68      0.49      1022\n",
      "weighted avg       0.92      0.66      0.75      1022\n",
      "\n",
      "Specificity: 0.6520833333333333\n",
      "Sensitivity: 0.7096774193548387\n"
     ]
    }
   ],
   "source": [
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_train_under, y_train_under = undersample.fit_resample(X_train, y_train)\n",
    "knn_model_under = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model_under.fit(X_train_under, y_train_under)\n",
    "y_pred_under_knn = knn_model_under.predict(X_test)\n",
    "accuracy_under_knn = accuracy_score(y_test, y_pred_under_knn)\n",
    "report_under_knn = classification_report(y_test, y_pred_under_knn)\n",
    "print(f'Z undersamplingiem:')\n",
    "print(f'DokÅ‚adnoÅ›Ä‡: {accuracy_over_knn:.2%}')\n",
    "print(f'Raport klasyfikacji: {report_under_knn}')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_under_knn)\n",
    "true_negatives = conf_matrix[0, 0]\n",
    "false_positives = conf_matrix[0, 1]\n",
    "\n",
    "specificity = true_negatives / (true_negatives + false_positives)\n",
    "print(f'Specificity: {specificity}')\n",
    "\n",
    "true_positives = conf_matrix[1, 1]\n",
    "false_negatives = conf_matrix[1, 0]\n",
    "\n",
    "sensitivity = true_positives / (true_positives + false_negatives)\n",
    "print(f'Sensitivity: {sensitivity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling dla algorytmu regresji logistycznej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z oversamplingiem:\n",
      "DodÅ‚adnoÅ›Ä‡: 73.58%\n",
      "Raport klasyfikacji:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.73      0.84       960\n",
      "           1       0.16      0.79      0.27        62\n",
      "\n",
      "    accuracy                           0.74      1022\n",
      "   macro avg       0.57      0.76      0.55      1022\n",
      "weighted avg       0.93      0.74      0.80      1022\n",
      "\n",
      "Specificity: 0.7322916666666667\n",
      "Sensitivity: 0.7903225806451613\n"
     ]
    }
   ],
   "source": [
    "oversampler = RandomOverSampler(sampling_strategy='minority')\n",
    "X_train_over, y_train_over = oversampler.fit_resample(X_train, y_train)\n",
    "logistic_regression_model_over = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logistic_regression_model_over.fit(X_train_over, y_train_over)\n",
    "y_pred_over_lr = logistic_regression_model_over.predict(X_test)\n",
    "accuracy_over_lr = accuracy_score(y_test, y_pred_over_lr)\n",
    "report_over_lr = classification_report(y_test, y_pred_over_lr)\n",
    "print(f'Z oversamplingiem:')\n",
    "print(f'DodÅ‚adnoÅ›Ä‡: {accuracy_over_lr:.2%}')\n",
    "print(f'Raport klasyfikacji: {report_over_lr}')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_over_lr)\n",
    "true_negatives = conf_matrix[0, 0]\n",
    "false_positives = conf_matrix[0, 1]\n",
    "\n",
    "specificity = true_negatives / (true_negatives + false_positives)\n",
    "print(f'Specificity: {specificity}')\n",
    "\n",
    "true_positives = conf_matrix[1, 1]\n",
    "false_negatives = conf_matrix[1, 0]\n",
    "\n",
    "sensitivity = true_positives / (true_positives + false_negatives)\n",
    "print(f'Sensitivity: {sensitivity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling dla algorytmu regresji logistycznej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z undersamplingiem:\n",
      "DokÅ‚adnoÅ›Ä‡: 73.19%\n",
      "Raport klasyfikacji:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.73      0.84       960\n",
      "           1       0.16      0.79      0.26        62\n",
      "\n",
      "    accuracy                           0.73      1022\n",
      "   macro avg       0.57      0.76      0.55      1022\n",
      "weighted avg       0.93      0.73      0.80      1022\n",
      "\n",
      "Specificity: 0.728125\n",
      "Sensitivity: 0.7903225806451613\n"
     ]
    }
   ],
   "source": [
    "undersampler = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_train_under, y_train_under = undersampler.fit_resample(X_train, y_train)\n",
    "logistic_regression_model_under = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logistic_regression_model_under.fit(X_train_under, y_train_under)\n",
    "y_pred_under_lr = logistic_regression_model_under.predict(X_test)\n",
    "accuracy_under_lr = accuracy_score(y_test, y_pred_under_lr)\n",
    "report_under_lr = classification_report(y_test, y_pred_under_lr)\n",
    "print(f'Z undersamplingiem:')\n",
    "print(f'DokÅ‚adnoÅ›Ä‡: {accuracy_under_lr:.2%}')\n",
    "print(f'Raport klasyfikacji: {report_under_lr}')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_under_lr)\n",
    "true_negatives = conf_matrix[0, 0]\n",
    "false_positives = conf_matrix[0, 1]\n",
    "\n",
    "specificity = true_negatives / (true_negatives + false_positives)\n",
    "print(f'Specificity: {specificity}')\n",
    "\n",
    "true_positives = conf_matrix[1, 1]\n",
    "false_negatives = conf_matrix[1, 0]\n",
    "\n",
    "sensitivity = true_positives / (true_positives + false_negatives)\n",
    "print(f'Sensitivity: {sensitivity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               0\n",
       "age                  0\n",
       "hypertension         0\n",
       "heart_disease        0\n",
       "ever_married         0\n",
       "work_type            0\n",
       "Residence_type       0\n",
       "avg_glucose_level    0\n",
       "bmi                  0\n",
       "smoking_status       0\n",
       "stroke               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DokÅ‚adnoÅ›Ä‡ LR: 92.17%\n",
      "Raport klasyfikacji dla modelu LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       960\n",
      "           1       0.31      0.24      0.27        62\n",
      "\n",
      "    accuracy                           0.92      1022\n",
      "   macro avg       0.63      0.60      0.62      1022\n",
      "weighted avg       0.91      0.92      0.92      1022\n",
      "\n",
      "Specificity: 0.9656\n",
      "Sensitivity: 0.2419\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Tworzenie modelu z dostosowanym stosunkiem klas\n",
    "# Ustawienie class_weight na 10:90 dla klasy 1:0\n",
    "logistic_regression_model = LogisticRegression(random_state=42, max_iter=1000, class_weight={0: 0.2, 1: 0.8})\n",
    "\n",
    "# Trenowanie modelu na oryginalnym zestawie danych\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Prognozowanie i ocena modelu\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(f'DokÅ‚adnoÅ›Ä‡ LR: {accuracy_lr:.2%}')\n",
    "\n",
    "# Raport klasyfikacji\n",
    "classification_report_lr = classification_report(y_test, y_pred_lr)\n",
    "print(f'Raport klasyfikacji dla modelu LR:\\n{classification_report_lr}')\n",
    "\n",
    "# Obliczanie specificity i sensitivity\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_lr)\n",
    "true_negatives, false_positives, false_negatives, true_positives = conf_matrix.ravel()\n",
    "\n",
    "specificity = true_negatives / (true_negatives + false_positives)\n",
    "print(f'Specificity: {specificity:.4f}')\n",
    "\n",
    "sensitivity = true_positives / (true_positives + false_negatives)\n",
    "print(f'Sensitivity: {sensitivity:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nowy rozkÅ‚ad klas: Counter({0: 6, 1: 4})\n",
      "DokÅ‚adnoÅ›Ä‡ LR: 85.03%\n",
      "Raport klasyfikacji dla modelu LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92       960\n",
      "           1       0.22      0.56      0.31        62\n",
      "\n",
      "    accuracy                           0.85      1022\n",
      "   macro avg       0.59      0.72      0.61      1022\n",
      "weighted avg       0.92      0.85      0.88      1022\n",
      "\n",
      "Specificity: 0.8688\n",
      "Sensitivity: 0.5645\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Ustawienie stosunku klasy pozytywnej do negatywnej na 10:90\n",
    "rus = RandomUnderSampler(sampling_strategy={0: 6, 1: 4}, random_state=42)\n",
    "X_train_res, y_train_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Sprawdzenie nowego rozkÅ‚adu klas\n",
    "print(f'Nowy rozkÅ‚ad klas: {Counter(y_train_res)}')\n",
    "\n",
    "# Trenowanie modelu na zbalansowanym zestawie danych\n",
    "logistic_regression_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logistic_regression_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Prognozowanie i ocena modelu\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(f'DokÅ‚adnoÅ›Ä‡ LR: {accuracy_lr:.2%}')\n",
    "\n",
    "# Raport klasyfikacji\n",
    "classification_report_lr = classification_report(y_test, y_pred_lr)\n",
    "print(f'Raport klasyfikacji dla modelu LR:\\n{classification_report_lr}')\n",
    "\n",
    "# Obliczanie specificity i sensitivity\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_lr)\n",
    "true_negatives, false_positives, false_negatives, true_positives = conf_matrix.ravel()\n",
    "\n",
    "specificity = true_negatives / (true_negatives + false_positives)\n",
    "print(f'Specificity: {specificity:.4f}')\n",
    "\n",
    "sensitivity = true_positives / (true_positives + false_negatives)\n",
    "print(f'Sensitivity: {sensitivity:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Ustawienie stosunku klasy pozytywnej do negatywnej na 10:90\n",
    "rus = RandomUnderSampler(sampling_strategy={0: 6, 1: 4}, random_state=42)\n",
    "X_train_res, y_train_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Sprawdzenie nowego rozkÅ‚adu klas\n",
    "print(f'Nowy rozkÅ‚ad klas: {Counter(y_train_res)}')\n",
    "\n",
    "# Trenowanie modelu na zbalansowanym zestawie danych\n",
    "logistic_regression_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logistic_regression_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Prognozowanie i ocena modelu\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(f'DokÅ‚adnoÅ›Ä‡ LR: {accuracy_lr:.2%}')\n",
    "\n",
    "# Raport klasyfikacji\n",
    "classification_report_lr = classification_report(y_test, y_pred_lr)\n",
    "print(f'Raport klasyfikacji dla modelu LR:\\n{classification_report_lr}')\n",
    "\n",
    "# Obliczanie specificity i sensitivity\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_lr)\n",
    "true_negatives, false_positives, false_negatives, true_positives = conf_matrix.ravel()\n",
    "\n",
    "specificity = true_negatives / (true_negatives + false_positives)\n",
    "print(f'Specificity: {specificity:.4f}')\n",
    "\n",
    "sensitivity = true_positives / (true_positives + false_negatives)\n",
    "print(f'Sensitivity: {sensitivity:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DokÅ‚adnoÅ›Ä‡ LR: 93.93%\n",
      "Raport klasyfikacji dla modelu LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       960\n",
      "           1       0.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.94      1022\n",
      "   macro avg       0.47      0.50      0.48      1022\n",
      "weighted avg       0.88      0.94      0.91      1022\n",
      "\n",
      "Specificity: 1.0000\n",
      "Sensitivity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KamilSarzyniak\\anaconda3\\envs\\py10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\KamilSarzyniak\\anaconda3\\envs\\py10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\KamilSarzyniak\\anaconda3\\envs\\py10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Tworzenie modelu z dostosowanym stosunkiem klas\n",
    "# Ustawienie class_weight na 90:10 dla klasy 0:1\n",
    "logistic_regression_model = LogisticRegression(random_state=42, max_iter=1000, class_weight={0: 7, 1: 3})\n",
    "\n",
    "# Trenowanie modelu na oryginalnym zestawie danych\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Prognozowanie i ocena modelu\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(f'DokÅ‚adnoÅ›Ä‡ LR: {accuracy_lr:.2%}')\n",
    "\n",
    "# Raport klasyfikacji\n",
    "classification_report_lr = classification_report(y_test, y_pred_lr)\n",
    "print(f'Raport klasyfikacji dla modelu LR:\\n{classification_report_lr}')\n",
    "\n",
    "# Obliczanie specificity i sensitivity\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_lr)\n",
    "true_negatives, false_positives, false_negatives, true_positives = conf_matrix.ravel()\n",
    "\n",
    "specificity = true_negatives / (true_negatives + false_positives)\n",
    "print(f'Specificity: {specificity:.4f}')\n",
    "\n",
    "sensitivity = true_positives / (true_positives + false_negatives)\n",
    "print(f'Sensitivity: {sensitivity:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
